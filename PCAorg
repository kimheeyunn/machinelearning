import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_validate
from sklearn.cluster import KMeans

# 과일 데이터 다운로드 하기
!wget https://bit.ly/fruits_300_data -O fruits_300.npy

fruits = np.load('fruits_300.npy')
fruits_2d = fruits.reshape(-1,100 * 100)

# 주성분 : 전체 데이터의 분산을 가장 잘 설명하는 성분
# 분산이 커져야 데이터 사이의 차이점이 명확해짐

pca = PCA(n_components = 50) # 몇 개의 특성으로 데이터의 차원을 줄일지
pca.fit(fruits_2d)


print(pca.components_.shape)

def draw_fruits(arr, ratio=1):
  n = len(arr)
  rows = int(np.ceil(n/10))
  cols = n if rows < 2 else 10
  fig, axs = plt.subplots(rows, cols, figsize=(cols*ratio, rows*ratio), squeeze = False)

  for i in range(rows):
    for j in range(cols):
      if i*10 + j < n:
        axs[i,j].imshow(arr[i*10+j], cmap='gray_r')
      axs[i, j].axis('off')
  plt.show()

draw_fruits(pca.components_.reshape(-1,100,100))

print(fruits_2d.shape)
